import numpy as np
from astropy.io import fits
from numpy import ones, zeros
from scipy import interpolate

t__e = np.arange(40.0, 202.0, 4.0) #actual range is 40-200 imaginaty units, ~20-100 keV (Te(keV)*1000/511keV is here)
t__bb = np.arange(0.00015, 0.0031, 0.00015) #this one is non-physical, we went for way_to_low Tbbs here, I will most probably delete results from too small Tbbs. This is Tbb(keV)/511keV, so these correspond to 0.07 - 1.5 keV, but our calculations don't work correctly for Tbb<<0.5 keV
tau__t = np.arange(0.5, 3.55, 0.1) 

NEnergy_i = 150
NZenith_i = 9

I_mighty = ones((len(t__e), len(t__bb), len(tau__t), NEnergy_i, NZenith_i)) #5D Intensity tensor[Te,Tbb,tau_t, Energy, Mu]
Q_mighty = ones((len(t__e), len(t__bb), len(tau__t), NEnergy_i, NZenith_i)) #5D Q-parameter tensor[Te,Tbb,tau_t, Energy, Mu]

def reading_table(): #routine that just reads fits tables to I_mighty and Q_mighty
    global I_mighty
    global Q_mighty
    p=0 #as we will not go over lenght_Te but just over values within t__e array, we'll need a counter for index corr. to Te
    for i in t__e:
        hdu = fits.open('CompSlab_%s.fits' %(i), mode='update')
        print('With CompSlab_%s.fits still works' %(i)) #just to see sth on the screen while the files are being opened
        for ii in range(0,len(t__bb)): #Tbb
            for iii in range(0,16): #that's tau_t
                science_data = hdu[(iii)*len(t__bb)+ii+1].data #this messy index leads to the correct "list" within FITS file
                data = np.transpose(science_data.field(1)) #we need to transpose them, because tables were generated by julia and read in python, and there languages have different "majoring" in rows or columns, afaik
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, NEnergy_i): #energy
                    for kkk in range(0,NZenith_i): #zenith angles
                        I_mighty[p, ii, iii, kk, kkk] = data[kk, kkk+1]#+1 is they way to avoid saving the first column of the fits files, which is accidentally always zero
                        Q_mighty[p, ii, iii, kk, kkk] = data2[kk, kkk+1]
        p +=1
    #now we do the same for 2nd and later 3rd table corr. to the same Te. 
    #Generally, 1st table contain data for small tau_T, 2nd one for middle tau_T, 3rd one for big tau_T. 
    p=0
    for i in t__e:
        hdu = fits.open('CompSlab_bigTe_%s.fits' %(i), mode='update')
        print('With CompSlab_bigTe_%s.fits still works' %(i))
        for ii in range(0,len(t__bb)):
            for iii in range(0,10):
                science_data = hdu[(iii)*len(t__bb)+ii+1].data 
                data = np.transpose(science_data.field(1))
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, NEnergy_i):
                    for kkk in range(0,NZenith_i):
                        I_mighty[p, ii, iii+16, kk, kkk] = data[kk, kkk+1]
                        Q_mighty[p, ii, iii+16, kk, kkk] = data2[kk, kkk+1]
        p +=1
    p=0            
    for i in t__e:
        hdu = fits.open('CompSlab_hugeT_%s.fits' %(i), mode='update')
        print('With CompSlab_hugeT_%s.fits still works' %(i)) 
        for ii in range(0,len(t__bb)):
            for iii in range(0,5):
                science_data = hdu[(iii)*len(t__bb)+ii+1].data 
                data = np.transpose(science_data.field(1))
                data2 = np.transpose(science_data.field(0))
                for kk in range(0, NEnergy_i):
                    for kkk in range(0,NZenith_i):
                        I_mighty[p, ii, iii+26, kk, kkk] = data[kk, kkk+1]
                        Q_mighty[p, ii, iii+26, kk, kkk] = data2[kk, kkk+1]
        p +=1


def interp(te, tbb, taut):
    I_3D = ones((len(t__e), len(t__bb), len(tau__t)))
    P_3D = ones((len(t__e), len(t__bb), len(tau__t))) #these two will contain values for I and A for all Te, Tbb and TauT, but E and mu are fixed. 
    I_2D = ones((NEnergy_i, NZenith_i))
    P_2D = ones((NEnergy_i, NZenith_i)) #these two will contain the interpolation results of log(I) and PD (Q/I) for specific values of Te, Tbb and TauT (given by the Task, one combination at a time) for all Es and mus.
    real_I_2D = ones((NEnergy_i, NZenith_i)) 
    Q_2D = ones((NEnergy_i, NZenith_i)) #with these two we're going back to values of I and Q parameters. 

    x = np.linspace(40.0, 200.0, 41) #that's the grid we're gonna use for the interpolation
    y = np.linspace(0.00015, 0.003, 20)
    z = np.linspace(0.5, 3.5, 31)
    points = (x, y, z)

    point = np.array([te, tbb, taut]) #and the point in which we want to have the interpolation

    for kk in range(0, NEnergy_i): #energy
        for kkk in range(0, NZenith_i): #zenith angles
            for i in range(0, len(t__e)): #Te
                for ii in range(0, len(t__bb)): #Tbb
                    for iii in range(0, len(tau__t)): #tau_T
                        I_3D[i, ii, iii] = np.log(I_mighty[i, ii, iii, kk, kkk]) #for making the function more smooth and easier to interpolate
                        P_3D[i, ii, iii]=Q_mighty[i, ii, iii, kk, kkk]/I_mighty[i, ii, iii, kk, kkk] #same, we go from Q-param to more "stable" polarization degree
            I_2D[kk,kkk]=interpolate.interpn(points, I_3D, point) 
            P_2D[kk,kkk]=interpolate.interpn(points, P_3D, point)
            real_I_2D[kk,kkk]=np.exp(I_2D[kk,kkk]) #going back to original quantities
            Q_2D[kk,kkk] = P_2D[kk,kkk]*real_I_2D[kk,kkk]
            #print(kk,kkk) #just a counter to see something happening on the screen while all the interpolations are happening ;)
    #Probably the only important thing to notice is that 2*1350 interpolations are done, not one. We have 5D tensor, do the 3D interpolation over Te, Tbb, tau_T - in each point of (Energy, Zenith angle) grid
    
    #I do this only because I needed these 2 matrices as 1 3D tensor for further pulse profiling
    I = zeros((NEnergy_i, NZenith_i, 2)) 
    I[:,:,0]=real_I_2D[:,:]
    I[:,:,1]=Q_2D[:,:]

    outI = open("CompI_int_py.bin","w")
    I.tofile(outI,format="%e")